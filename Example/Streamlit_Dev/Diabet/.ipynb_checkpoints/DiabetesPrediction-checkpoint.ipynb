{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81268771",
   "metadata": {},
   "source": [
    "# Diabetes Prediction using ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82e0f9",
   "metadata": {},
   "source": [
    "## Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e699b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC                                  #importing support vector regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc1cca",
   "metadata": {},
   "source": [
    "# Data collection and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b03e7",
   "metadata": {},
   "source": [
    "## Pima dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9511c8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/_rsc33_d1j98brvvjfdzhnzw0000gn/T/ipykernel_3392/456508922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diabetes.csv'"
     ]
    }
   ],
   "source": [
    "db_df = pd.read_csv('https://raw.githubusercontent.com/1Abneesh/DiagnosticAI/master/Datasets/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7160cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the number of Number of rows and colmns of dataset\n",
    "db_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking the top 5 data of dataset\n",
    "db_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a46efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the statistical measure of data\n",
    "db_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db_df\n",
    "fig, ax = plt.subplots(4, 2, figsize = (20, 15))\n",
    "plt.suptitle('Distribution of Numerical features based on target variable', fontsize = 25, color = 'teal')\n",
    "sn.histplot(x = data['Pregnancies'], hue= data['Outcome'], kde= True, ax= ax[0,0], palette = 'ocean')\n",
    "ax[0,0].set(xlabel = 'Pregnancies')\n",
    "sn.histplot(x = data['Glucose'], hue= data['Outcome'], kde= True, ax= ax[0,1], palette = 'twilight')\n",
    "ax[0,1].set(xlabel = 'Glucose')\n",
    "sn.histplot(x = data['BloodPressure'], hue= data['Outcome'], kde= True, ax= ax[1,0], palette = 'viridis')\n",
    "ax[1,0].set(xlabel = 'Blood Pressure')\n",
    "\n",
    "sn.histplot(x = data['SkinThickness'], hue= data['Outcome'], kde= True, ax= ax[1,1], palette = 'Pastel2_r')\n",
    "ax[1,1].set(xlabel = 'Skin Thickness')\n",
    "sn.histplot(x = data['Insulin'], hue= data['Outcome'], kde= True, ax= ax[2,0], palette = 'gnuplot')\n",
    "ax[2,0].set(xlabel = 'Insulin')\n",
    "sn.histplot(x = data['BMI'], hue= data['Outcome'], kde= True, ax= ax[2,1], palette = 'twilight_shifted')\n",
    "ax[2,1].set(xlabel = 'BMI')\n",
    "\n",
    "sn.histplot(x = data['DiabetesPedigreeFunction'], hue= data['Outcome'], kde= True, ax= ax[3,0], palette = 'RdPu_r')\n",
    "ax[3,0].set(xlabel = 'Diabetes Pedigree Function')\n",
    "sn.histplot(x = data['Age'], hue= data['Outcome'], kde= True, ax= ax[3,1], palette = 'mako')\n",
    "ax[3,1].set(xlabel = 'Age')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e20e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheching for empty value in dataset\n",
    "db_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a heatmap to check for null value\n",
    "plt.figure(figsize=(15,15))\n",
    "sn.heatmap(db_df.isnull()) #since we get heatmap of uniform colour so no data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf89918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data in dataset for true or false data\n",
    "db_df_shpe = db_df['Outcome'].value_counts()\n",
    "print('The total data not having diabetes:-{}\\nThe total data having diabetes:-{}'.format(db_df_shpe[0],db_df_shpe[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e141560",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x = data['Outcome'], palette= 'winter')\n",
    "plt.xlabel('Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting more analysis of our data\n",
    "db_df.groupby('Outcome').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seprating the data and labels\n",
    "X = db_df.drop(['Outcome'],axis=1)\n",
    "y = db_df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cac5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f13b2",
   "metadata": {},
   "source": [
    "# Creating a correlational matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "heatmap = sn.heatmap(db_df.corr(),annot=True,cmap=\"YlGnBu\");\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33674196",
   "metadata": {},
   "source": [
    "## Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()\n",
    "X_standardised = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ecbe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e9fb45",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a24cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test,y_train,y_test = train_test_split(X_standardised,y,test_size=0.2,random_state=12,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77584a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The original data shape is {}. Test data shape {} and train data shape is {}'.format(X.shape,X_train.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b75aaf",
   "metadata": {},
   "source": [
    "## Selecting the best possible model with hyperperameters between logestic_regression and support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c287d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'logestic_regression' :{\n",
    "        'model' : LogisticRegression(),\n",
    "         'params' :{\n",
    "             'penalty':['l1', 'l2', 'elasticnet', None],\n",
    "             'C':[-7,1e-2,0,1,2,3,4,5,6,7,8,9,10,20,30,40,50],\n",
    "             'max_iter':[10,50,100,200,300,500],\n",
    "             'tol':[1e-5,1e-4,1e-6,1e-8]\n",
    "      }\n",
    "  },\n",
    "    'SVC':{\n",
    "     'model' : SVC(),\n",
    "     'params':{\n",
    "         'gamma':['auto','scale'],\n",
    "         'C':[-7,1e-2,0,1,2,3,4,5,6,7,8,9,10,20,30,40,50],\n",
    "         'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "         'coef0':[0.0,0.5,0.7,0.9,1.0,2.0]  \n",
    "     }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for model_name,mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'],mp['params'],cv =5,return_train_score=False)\n",
    "    clf.fit(X_train,y_train)\n",
    "    scores.append({\n",
    "        'model':model_name,\n",
    "        'best_score':clf.best_score_,\n",
    "        'best_params':clf.best_params_,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccdc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.DataFrame(scores,columns=['model','best_score','best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b684a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64eb38",
   "metadata": {},
   "source": [
    "# Therefore on comparing the perfomance of both the model we conlude that svc work better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00940dd",
   "metadata": {},
   "source": [
    "### Model evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d35a91",
   "metadata": {},
   "source": [
    "#### Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75313f16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/_rsc33_d1j98brvvjfdzhnzw0000gn/T/ipykernel_3392/981265372.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mres2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "y_test_predict = clf.predict(X_test)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "res1= accuracy_score(y_test_predict,y_test)\n",
    "res2 = accuracy_score(y_train_predict,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e73ea02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/_rsc33_d1j98brvvjfdzhnzw0000gn/T/ipykernel_3392/3520004700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy score on test is {} and train data for our model is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res1' is not defined"
     ]
    }
   ],
   "source": [
    "print('Accuracy score on test is {} and train data for our model is {}'.format(res1,res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a539c262",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/_rsc33_d1j98brvvjfdzhnzw0000gn/T/ipykernel_3392/3756772113.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#creating the confusion matrix for train data checking the accuracy of our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcm\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "#creating the confusion matrix for train data checking the accuracy of our model\n",
    "cm= confusion_matrix(y_true = y_train,y_pred=y_train_predict)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm,annot=True,fmt='d')\n",
    "plt.xlabel('Predected')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bb70d7",
   "metadata": {},
   "source": [
    "## Making a predictive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad2d09c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/_rsc33_d1j98brvvjfdzhnzw0000gn/T/ipykernel_3392/206092136.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#standarised the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0minput_data_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "input_data = (5,187,76,27,207,43.6,1.034,53)\n",
    "\n",
    "# changing the input_data to numpy array\n",
    "input_data = np.asarray(input_data)\n",
    "\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data = input_data.reshape(1,-1)\n",
    "\n",
    "#standarised the data\n",
    "input_data_std = scaler.transform(input_data)\n",
    "print(input_data_std)\n",
    "\n",
    "prediction = clf.predict(input_data_std)\n",
    "if prediction[0] == 1:\n",
    "    print('The patient has Diabetes')\n",
    "else:\n",
    "    print('The patient has not Diabatese')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40391d96",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b36e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the scaler and model\n",
    "filename = 'diabetes_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "scalerfile = 'scaler.sav'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd198c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "load_model = pickle.load(open('diabetes_model.sav', 'rb'))\n",
    "load_scaler = pickle.load(open('scaler.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03c382ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before input data [[  5.    104.     74.      0.      0.     28.8     0.153  48.   ]]\n",
      "after std input data [[ 0.3429808  -0.5287506   0.25303625 -1.28821221 -0.69289057 -0.40519961\n",
      "  -0.96304428  1.2558199 ]]\n",
      "\n",
      "The patient has not Diabatese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\01abn\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_data = (5,104,74,0,0,28.8,0.153,48)\n",
    "\n",
    "# changing the input_data to numpy array\n",
    "input_data = np.asarray(input_data)\n",
    "\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data = input_data.reshape(1,-1)\n",
    "\n",
    "#standarised the data\n",
    "print('before input data',input_data)\n",
    "input_data_std = load_scaler.transform(input_data)\n",
    "print('after std input data',input_data_std)\n",
    "print()\n",
    "prediction = clf.predict(input_data_std)\n",
    "if prediction[0] == 1:\n",
    "    print('The patient has Diabetes')\n",
    "else:\n",
    "    print('The patient has not Diabatese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "111fb9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies\n",
      "Glucose\n",
      "BloodPressure\n",
      "SkinThickness\n",
      "Insulin\n",
      "BMI\n",
      "DiabetesPedigreeFunction\n",
      "Age\n",
      "Outcome\n"
     ]
    }
   ],
   "source": [
    "for col in db_df:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4407b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b2afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
